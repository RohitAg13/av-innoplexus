{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:05:48.863816Z",
     "start_time": "2019-07-28T14:05:48.401495Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:05:51.008825Z",
     "start_time": "2019-07-28T14:05:48.870132Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit,StratifiedKFold, RepeatedStratifiedKFold\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from scipy.sparse import hstack\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:05:51.056695Z",
     "start_time": "2019-07-28T14:05:51.012870Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_score(y_valid, valid_pred):\n",
    "    print(f\"f1_score : {f1_score(y_valid, valid_pred,average='macro')}\")\n",
    "    print(f\"accuracy: {accuracy_score(y_valid, valid_pred)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:05:51.546133Z",
     "start_time": "2019-07-28T14:05:51.505500Z"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "TEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:06:27.486218Z",
     "start_time": "2019-07-28T14:06:00.229017Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = (TextList.from_csv(path, 'train.csv', cols='text')\n",
    "                         .split_none()\n",
    "                         .label_from_df(cols=3))\n",
    "\n",
    "#######DURING TEST#######\n",
    "if TEST:\n",
    "    reviews.add_test(TextList.from_csv(path, 'test.csv', cols='text'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:06:28.169890Z",
     "start_time": "2019-07-28T14:06:27.491810Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(path/'train.csv')\n",
    "#######DURING TEST#######\n",
    "if TEST:\n",
    "    test_df = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRUGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:06:32.051808Z",
     "start_time": "2019-07-28T14:06:31.990122Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.drop('unique_hash',axis=1,inplace=True)\n",
    "if TEST: test_df.drop('unique_hash',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T14:47:36.897903Z",
     "start_time": "2019-07-27T14:47:36.852096Z"
    },
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "features = [feature_exists,feature_count,feature_length,\n",
    "            feature_others,feature_other_exists]\n",
    "\n",
    "for feature in tqdm(features):\n",
    "    train_df[feature.__name__] = train_df[['text','drug']].apply(feature,axis=1)\n",
    "    if TEST:\n",
    "        test_df[feature.__name__] = test_df[['text','drug']].apply(feature,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:07:43.807834Z",
     "start_time": "2019-07-28T14:07:42.692847Z"
    }
   },
   "outputs": [],
   "source": [
    "train_texts, valid_texts, y_train, y_valid = \\\n",
    "        train_test_split(reviews.train.x, reviews.train.y.items, random_state=17)\n",
    "\n",
    "#######DURING TEST#######\n",
    "if TEST: train_texts, valid_texts, y_train, y_valid = reviews.train.x,reviews.test.x,reviews.train.y.items,reviews.test.y.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:07:50.607151Z",
     "start_time": "2019-07-28T14:07:45.243054Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = reviews.train.x\n",
    "train_words = [[docs.vocab.itos[o] for o in doc.data] for doc in train_texts]\n",
    "valid_words = [[docs.vocab.itos[o] for o in doc.data] for doc in valid_texts]\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1,1),preprocessor=noop, tokenizer=noop)\n",
    "trn_term_doc = vec.fit_transform(train_words)\n",
    "test_term_doc = vec.transform(valid_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:07:50.654094Z",
     "start_time": "2019-07-28T14:07:50.610922Z"
    }
   },
   "outputs": [],
   "source": [
    "y = reviews.train.y\n",
    "\n",
    "positive = y.c2i[0]\n",
    "negative = y.c2i[1]\n",
    "neutral  = y.c2i[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:07:51.026148Z",
     "start_time": "2019-07-28T14:07:50.971358Z"
    }
   },
   "outputs": [],
   "source": [
    "def pr(y_i, y):\n",
    "    p = np.squeeze(np.asarray(x[y==y_i].sum(0)))\n",
    "    return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "def get_mdl(x,y):\n",
    "    r = np.log(pr(True,y) / pr(False,y))\n",
    "    m = LogisticRegression(C=1, dual=True,solver='liblinear',class_weight='balanced')\n",
    "    x_nb = x.multiply(r)\n",
    "#     X_train = hstack([x_nb, X_train_drugs,train_features])\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:08:25.291015Z",
     "start_time": "2019-07-28T14:08:24.121360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit 0\n",
      "fit 1\n",
      "fit 2\n"
     ]
    }
   ],
   "source": [
    "x = trn_term_doc\n",
    "test_x = test_term_doc\n",
    "\n",
    "label_cols = [positive, negative, neutral]\n",
    "preds = np.zeros((test_term_doc.shape[0], len(label_cols)))\n",
    "preds_trn = np.zeros((x.shape[0], len(label_cols)))\n",
    "\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit', j)\n",
    "    m,r = get_mdl(x,y_train == j)\n",
    "    \n",
    "    x_nb_test = test_x.multiply(r)\n",
    "    X_valid = hstack([x_nb_test])\n",
    "    preds[:,i] = m.predict_proba(X_valid)[:,1]\n",
    "\n",
    "predictions = np.argmax(preds,axis=1)\n",
    "if not TEST:get_score(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:09:08.701972Z",
     "start_time": "2019-07-28T14:09:08.651384Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred_NB',preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:12:36.247384Z",
     "start_time": "2019-07-28T14:12:36.180956Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_meta = np.load('pred_meta.npy')\n",
    "pred_NB = np.load('pred_NB.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:16:39.015147Z",
     "start_time": "2019-07-28T14:16:38.962001Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions2 = np.argmax(0.3 * pred_meta  + 0.7 *pred_NB,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T16:54:28.807894Z",
     "start_time": "2019-07-27T16:54:27.018063Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit 0\n",
      "fit 1\n",
      "fit 2\n",
      "F1_score: 0.4649968826266031\n",
      "fit 0\n",
      "fit 1\n",
      "fit 2\n",
      "F1_score: 0.4846167950128346\n",
      "fit 0\n",
      "fit 1\n",
      "fit 2\n",
      "F1_score: 0.44431495601500126\n",
      "Final F1_score: 0.48160290246319165\n"
     ]
    }
   ],
   "source": [
    "################# K-FOLD ##################3\n",
    "# x = trn_term_doc\n",
    "# test_x = test_term_doc\n",
    "\n",
    "# skf = StratifiedKFold()\n",
    "\n",
    "# label_cols = [positive, negative, neutral]\n",
    "# preds = np.zeros((test_term_doc.shape[0], len(label_cols)))\n",
    "# for u,v in skf.split(x,y_train):\n",
    "#     X_trn, X_tst = x[u], x[v]\n",
    "#     y_trn, y_tst = y_train[u], y_train[v]\n",
    "#     preds_val = np.zeros((y_tst.shape[0], len(label_cols)))\n",
    "    \n",
    "#     for i, j in enumerate(label_cols):\n",
    "#         print('fit', j)\n",
    "#         m,r = get_mdl(X_trn,y_trn == j)\n",
    "\n",
    "#         preds_val[:,i] = m.predict_proba(X_tst.multiply(r))[:,1]\n",
    "#         preds[:,i] += m.predict_proba(test_x.multiply(r))[:,1]\n",
    "\n",
    "#     val_preds = np.argmax(preds_val,axis=1)\n",
    "#     print(f\"F1_score: {f1_score(y_tst,val_preds,average='macro')}\")\n",
    "\n",
    "# predictions = np.argmax(preds,axis=1)\n",
    "# print(f\"Final F1_score: {f1_score(y_valid,predictions,average='macro')}\")\n",
    "# # get_score(y_valid,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|f1_score|accuracy| Summary|\n",
    "|---|---|---|\n",
    "|0.4425933158406717|0.6977272727272728| baseline\n",
    "|0.4427632571071596|0.7| CountVectorizer\n",
    "|0.3454188866557859|0.7204545454545455| CountVectorizer-ngram(1,2)\n",
    "|0.44433905378177824|0.7007575757575758| CountVectorizer + Drug\n",
    "|0.3602603402216243 | 0.7265151515151516| Tf-idf + Drug\n",
    "|0.47709544489951083 | 0.678 | class_weight=balanced\n",
    "|0.438708402946439 | 0.6946969696969697 | feature_engineering\n",
    "|0.47644661545431627 |0.6803030303030303 | feature_engeneering+ balanced\n",
    "|0.4715854875669423|0.6734848484848485 | basline + balanced\n",
    "|0.50|0.687| tf-idf 1,1 balanced\n",
    "|0.42883925131396183|0.720454545454545| tf-ids 1,2 balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:16:47.233495Z",
     "start_time": "2019-07-28T14:16:47.148834Z"
    }
   },
   "outputs": [],
   "source": [
    "#######DURING TEST#######\n",
    "I+=1\n",
    "path_sub =Path('Submissions')\n",
    "sample = pd.read_csv(path/'sample_submission.csv')\n",
    "sample['sentiment'] = predictions3\n",
    "sample.to_csv(path_sub/f'submission{I}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T14:14:52.959321Z",
     "start_time": "2019-07-28T14:14:52.915101Z"
    }
   },
   "outputs": [],
   "source": [
    "I = 16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
